\section{Contributions}

\subsection{Introduction} 
Cette section présente les démarches de recherche qui ont été effectué durant le stage.\\
Dans un premier temps, nous proposons et définissons des critères qui permettent d'identifier si une instance est difficile ou non.\\
Ensuite, nous abordons la résolution du MIN-PCM avec deux approches différentes :
\begin{itemize}
\item Une recherche exacte qui à la possibilité de prouver la borne minimum du MIN-PCM sur des instances de taille raisonnable.
\item Une recherche approché qui à la possibilité de trouver des solutions de bonne qualité mais non nécessairement optimal, en un temps polynômial sur des instance de grande taille.
\end{itemize} 
%\textit{TODO: Enfin, nous générons des instances pseudo-aléatoire de différents degrés de difficultés que nous soumettons à nos algorithmes.}

\subsection{Définition d'une instance difficile}
Prenons deux instances: une réelle (rch10) et une aléatoire (s3836-0), voici leurs caractéristiques:
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline 
Instances & Entités & Groupes & Gènes & Résolution PL & Résolution EPC\footnote{[Exact-Proj-Car CHHEL et al]} \\ 
\hline 
s3836-0 & 1000 & 15 & 1000 & - & 16 \\ 
\hline
rch10 & 173 & 27 & 98 & \textbf{10}\footnote{En gras = solution optimal} & 14 \\ 
\hline
\end{tabular} 
\end{center}
\vspace{7mm}

A priori, on peut supposer que l'instance aléatoire est plus difficile à résoudre: elle est bien plus volumineuse que l'instance réelle à tel point qu'elle nécessite plus de 32 Go de RAM pour une résolution en programmation linéaire.

Observons leurs résolutions avec notre algorithme sans heuristique présenté dans la figure \ref{algoMinPCM} page \pageref{algoMinPCM})
\begin{figure}[H]
\centering
	\begin{minipage}[c]{0.49\linewidth}
	\centering
	\input{./figure/sh_rch10_s3836_nbComp.tex}
	\end{minipage}
	\begin{minipage}[c]{0.49\linewidth}
	\centering
	\input{./figure/sh_rch10_s3836_temps.tex}
	\end{minipage}
\caption{Résolution sans heuristique de rch10 et s3836-0}
\end{figure} 

Nous apercevons que l'instance aléatoire est facilement résolu jusqu'à une caractérisation de taille 15. Ce n'est pas le cas de l'instance réelle qui ne peut plus caractériser en un temps raisonnable à partir d'une caractérisation de taille 25. Ce type d'observation étant \textbf{systématique} quelque soit les caractéristiques des instances réelles ou aléatoire comparés, nous pouvons alors affirmer que la taille d'une instance ne suffit pas à elle seule pour définir sa difficulté. Dès lors, nous nous posons les deux questions suivantes:\\

\begin{itemize}
\item \textbf{Qu'est ce qui peut bien être à l'origine de cette différence de résolution entre une instance aléatoire et une instance réelle?}
\item \textbf{Existe il une méthode permettant de définir si une instance est difficile à résoudre ou non ?}\\
\end{itemize}
Afin de répondre à ces questions, nous définissons les notions suivantes:

\begin{definition}
Le \textbf{masque $M$ d'un groupe $g$} correspond à la moyenne des présences/absences des gènes pour chaque entité du groupe.\\
Formellement, soit $M_g$ le masque d'un groupe $g$, $g \in \mathcal{G}$, $M_g[i]$ la valeur du masque $g$ en position $i$, $i \in [1,|\mathcal{X}|]$,
% $|\mathcal{X}|$ étant le nombre de gènes de l'instance après la suppression des redondances,
$$\forall i \in  [1, |\mathcal{X}|], M_g[i]= \frac{\sum_{i=1}^{|\mathcal{G}|}e_i}{|\mathcal{G}|} $$
\end{definition}

\begin{definition}
Le \textbf{ratio $r$ d'un masque $M$} correspond au pourcentage de valeur entière (0/1) présentent dans le masque.\\
Formellement, soit $M_g$ le masque d'un groupe $g$, $r_g(I)$ le ratio du groupe $g$ dans l'image $I$, $g \in \mathcal{G}$,
\begin{center}
$$ r_g(I)=\frac{|{i / M_g[i] \in \{0,1\}}|}{|\mathcal{X}|},\forall i \in [1,|\mathcal{X}|]$$
\end{center}
\end{definition}

%\subsubsection*{Exemple :}
\begin{exemple}{Masque et ratio d'un groupe\\}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
\backslashbox{Entités}{Gènes} & g0 & g1 & g2 & g3 & g4 & g5 & g6 & g7 & g8 & g9 \\ 
\hline 
e1 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 0 & 0 & 1 \\ 
\hline 
e2 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 1 \\ 
\hline 
e3 & 1 & 1 & 0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\ 
\hline 
e4 & 1 & 1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 & 0 \\ 
\hline 
e5 & 1 & 1 & 0 & 1 & 1 & 1 & 0 & 1 & 0 & 0 \\ 
\hline 
\hline
Masque & 1 & 1 & 0 & 0.8 & 0.6 & 1 & 0 & 0.4 & 0 & 0.4 \\
\hline
\end{tabular}
\end{center}
Le ratio $r$ de ce groupe est : \\
$r=6/10$\\
soit  $r=0.6$
\end{exemple}

\begin{definition}
L'\textbf{image $I$ d'une instance} est une matrice en deux dimensions de taille $|\mathcal{G}|*|\mathcal{X}|$ où chaque ligne correspond au masque de chacun des groupes de l'instance.\\
Formellement, soit $I_g$ la ligne g de la matrice $I$ correspondant à l'image de l'instance $\mathcal{I}$, $M_g$ le masque du groupe $g$ de l'instance $\mathcal{I}$,
$$\forall g \in [1,|\mathcal{G}|], I_g=M_g$$
\end{definition}


\begin{definition}
Le \textbf{taux de similarité $\mathcal{T}_j$ d'un gène $j$} correspond à la moyenne des valeurs de la colonne $j$ sur l'image $I$ d'une instance $\mathcal{I}$.\\
Formellement, soit $I$ l'image d'une instance $\mathcal{I}$, $i$ la $i$\up{ème} ligne de $I$, $j$ la $j$\up{ème} colonne de $I$, $I_{ij}$ est la valeur dans $I$ en ligne $i$ et en colonne $j$, $\mathcal{T}_j(I)$ le taux de similarité globale du gène $j$ dans l'image $I$,
$$ \text{Soit } X=\frac{\sum_{i=1}^{|\mathcal{G}|} I_{ij}}{\mathcal{G}} $$ 
$$\text{Si } X<0.5 \text{ alors } \mathcal{T}_j(I)=(0.5-X)*2 $$
$$\text{sinon }\mathcal{T}_j(I)=(0.5-(1-X))*2$$ 
\end{definition}
Ainsi formuler, $\mathcal{T}_j(I) \in [0,1]$, et, plus le taux de similarité d'un gène est élevé, plus sa présence(resp. abscence) dans l'instance est redondante.

\begin{definition}
Le \textbf{coefficient de difficulté $\rho$ d'une instance}, correspond à la moyenne des taux de similarité globaux d'une instance.\\
Formellement, soit $I$ l'image d'une instance $\mathcal{I}$, $j$ la $j$\up{ème} colonne de $I$, $\mathcal{T}_j(I)$ le taux de similarité globale du gène $j$ dans l'image $I$,
$$ \rho=\frac{\sum_{j=1}^{|\mathcal{X}|}\tau_j(I)}{|\mathcal{X}|} $$
\end{definition}

\begin{definition}
Le \textbf{coefficient de difficulté $\sigma$ d'une instance}, correspond au complémentaire de la moyenne des ratios des masques d'une instance\footnote{La moyenne des ratios des masques d'une instance $\in [0,1]$ }. Nous utilisons le complémentaire de façon à ce que l'interprétation du coefficient $\sigma$ soit calqué sur celui de $\rho$.
Formellement, soit $I$ l'image d'une instance $\mathcal{I}$, $i$ la $i$\up{ème} ligne de $I$, $r_i(I)$ le ratio du groupe $i$ dans l'image $I$,
$$ \sigma=1-\frac{\sum_{i=1}^{|\mathcal{G}|}r_i(I)} {|\mathcal{G}|} $$
\end{definition}

\begin{definition}
\textbf{Le coefficient $\Delta\cal{T}$ d'une instance} correspond à l'écart type des taux de similarité $\cal{T}$ des gènes.
Formellement, soit $I$ l'image d'une instance $\mathcal{I}$, $i$ la $i$\up{ème} ligne de $I$, $r_i(I)$ le ratio du groupe $i$ dans l'image $I$, le coefficient de difficulté $\rho$ de l'instance $\cal{I}$, 
$$\Delta\mathcal{T}=\sqrt{\frac{\sum_{j=1}^{|\mathcal{X}|} (\rho-\mathcal{T}_j)^2}{|\mathcal{X}|}}$$
$$\Delta\mathcal{T} \in [0,\frac{1}{2}]$$
\end{definition}

\begin{remarque}
	Si $\rho \simeq 0$ (resp. 1) alors $\Delta\cal{T} \simeq $ 0 car $\rho$ est la moyenne des taux de similarité $\cal{T}$ d'une instance et si cette moyenne est proche de 0 (resp. 1), cela signifie que la majorité des $\cal{T}$ sont proche de 0 (resp. 1) et donc que leur écart type ($\Delta\cal{T}$) est proche de 0.
	\label{remDeltaTau}
\end{remarque}


Reprenons nos deux instances rch10 et s3836-0 et calculons leurs coefficients de difficultés:

\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline 
Instances & $\Delta\cal{T} $ & $\rho$ & $\sigma$ \\ 
\hline 
s3836-0 & 0.019 & 0 & 0.024 \\ 
\hline
rch10 & 0.238 & 0.626 & 0.906 \\ 
\hline
\end{tabular} 
\end{center}

Nous observons que le coefficient de difficulté $\rho$ semble plus significatif que $\sigma$ pour déterminer la difficulté d'une instance, mais nous ne sommes pas en mesure d'indiquer dans quel proportions. Cependant les travaux de \cite{Chhel2013} nous indiquent que seul une heuristique sur le choix des variables est en mesure de pouvoir améliorer un algorithme de recherche exacte. Cela nous conforte dans l'idée que $\rho$ a plus d'influence que $\sigma$ sur la difficulté d'une instance. Nous pouvons ainsi formuler les deux propositions suivante:

\begin{proposition}
Une instance dont le coefficient de difficulté $\rho$ est proche de 1 est une \textbf{instance difficile} à résoudre.
\end{proposition}

\begin{proposition}
Une instance dont le coefficient de difficulté $\rho$ est proche de 1 et dont le coefficient de difficulté $\sigma$ est proche de 1 est une \textbf{instance très difficile} à résoudre.
\end{proposition}

Dès lors, nous pourrions penser qu'il suffit de trouver une heuristique basée sur le choix des gènes en fonction de leurs taux de similarité $\cal{T}$ pour outrepasser la difficulté émise par le coefficient $\rho$. Ce n'est pas le cas. En effet, si l'écart type entre les différents taux $\cal{T}$ d'une instance est faible, alors le critere $\cal{T}$ ne permet pas de différencier significativement les gènes. Nous faisons donc la proposition suivante: 

\begin{proposition}
Une heuristique basée sur le choix des gènes en fonction de leurs taux de similarité $\cal{T}$ n'a aucune influence sur des instances dont le coefficient $\Delta\cal{T}$ est proche de 0.
\label{propDelta}
\end{proposition}

Il y a encore au moins un indicateur sur la difficulté des instances: il s'agit de la taille de celles-ci. Nous rejoignons l'idée émise dans \cite{Chhel2013}, selon laquelle la taille d'une instance est caractérisé par son nombre de gènes et d'entités mais pas par son nombre de groupe. Cependant, lorsque le coefficient de difficulté $\sigma$ est proche de 0, nous devrions pouvoir être en mesure d'outrepasser cette difficulté puisque nous pouvons réduire le parcours d'un très grand nombre d'entités par l'utilisation des masques, nous présentons ce cas de figure dans l'exemple \ref{exempleDifficulté}. Nous faisons donc la proposition suivante:



\begin{proposition}
La taille d'une instance est une information sur la difficulté de sa résolution. Il n'existe pas d'heuristique permettant d'outrepasser cette difficulté lorsque le coefficient $\sigma$ de l'instance est proche de 1.
\end{proposition}

\begin{exemple}[Difficultées d'une instance]
Supposons qu'il existe une instance composé de 3 groupes de 100 entités que l'on souhaite caractériser avec un ensemble de $n$ gènes. Supposons également que cette instance ait pour coefficients de difficulté $\sigma \simeq 0$, $\rho \simeq 0.7$ et $\Delta\cal{T} \simeq$ 0. D'après notre proposition \ref{propDelta}, il n'existe pas d'heuristique efficace pour outrepasser la difficulté émise par $\rho$.

Une recherche standard pour une caractérisation de taille $k$ effectue au maximum environ $ (100*200 + 100*100) * C_n^k * k$ comparaisons. Comme $sigma \simeq 0$ , nous pouvons exploiter les masques. En les utilisant, nous effectuons au maximum environ $ (1\up{+} * 2\up{+} + 1\up{+}*1\up{+}) * C_n^k * k $ comparaisons.

On remarque que dans ce cas précis, l'utilisation des masques à une influence sur la résolution du problème.

Supposons maintenant que $\Delta\cal{T} \simeq $ 0.5, nous présumons dès lors que l'efficacité d'une heuristique basée sur l'utilisation des masques serait bien dérisoire face à une heuristique basée sur le choix des gènes en fonction de leurs taux de similarité $\cal{T}$\footnote{Quoique cette assertion dépend de la valeur de $n$}. En effet, une heuristique basée sur le choix des gènes en fonction de leurs taux de similarité $\cal{T}$ travaille à réduire le facteur à caractère exponentiel $C_n^k$ alors que l'utilisation des masques vise à réduire un facteur à caractère polynômial. Cela confirme une fois de plus que $\rho$ à plus d'influence que $\sigma$ pour caractériser une instance.
\label{exempleDifficulté}
\end{exemple}


%Les observations sur notre jeu de 15 instances nous permettent de conclure que $\sigma$ en particulier, et $\rho$ dans une moindre mesure, nous permettent de définir ce qu'est une instance difficile. 

\subsubsection{Observations}

Nous présentons ici les instances avec leurs coefficients de difficultés respectifs:
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline 
Instances & Entités & Gènes & $\Delta\cal{T}$ & $\rho$ & $\sigma$ & PL & EPC & LSPC \\ 
\hline 
s301-0 & 500 & 400 & 0.025 & 0.034 & 0.999 & - & 13 & 14 \\ 
\hline 
s326-0 & 500 & 500 & 0.026 & 0.033 & 1 & - & 13 & 14 \\ 
\hline 
s413-30 & 500 & 600 & 0.027 & 0.035 & 1 & - & 13 & 13 \\ 
\hline 
s555-20 & 800 & 800 & 0.029 & 0.039 & 0.999 & - & 13 & 13 \\ 
\hline 
s625-20 & 500 & 1000 & 0.027 & 0.035 & 1 & - & 13 & 13 \\ 
\hline 
s754-10 & 600 & 200 & 0.027 & 0.034 & 1 & - & 13 & 14 \\ 
\hline 
s882-20 & 600 & 400 & 0.024 & 0.032 & 1 & - & 13 & 14 \\ 
\hline 
s2501-70 & 800 & 800 & 0.024 & 0.033 & 1 & - & 15 & 15 \\ 
\hline 
s31294-50 & 200 & 1000 & 0.049 & 0.065 & 0.993 & 10 & 10 & 11 \\ 
\hline 
s3836-0 & 1000 & 1000 & 0.019 & 0.024 & 1 & - & 16 & 16 \\ 
\hline 
raphv & 108 & 68 & 0.302 & 0.588 & 0.419 & \textbf{6} & \textbf{6} & 9 \\ 
\hline 
raphy & 112 & 70 & 0.294 & 0.609 & 0.668 & \textbf{6} & \textbf{6} & 8 \\ 
\hline 
rarep & 112 & 72 & 0.295 & 0.651 & 0.502 & \textbf{12} & 39 & 14 \\ 
\hline 
rch8 & 56 & 27 & 0.339 & 0.569 & 0.067 & \textbf{9} & \textbf{9} & 9 \\ 
\hline 
rch10 & 112 & 86 & 0.238 & 0.626 & 0.094 & \textbf{10} & 25 & 15 \\ 
\hline 
\end{tabular} 
\end{center}

Toute les instances aléatoires ont un coefficient $\rho$ proche de 0 et donc un coefficient $\Delta\cal{T}$ proche de 0 (voir remarque \ref{remDeltaTau}). Mais elles ont pour difficulté leurs coefficients $\sigma$ qui est proche de 1, cela signifie que nous ne pourrons pas réduire de façon significative leurs temps de résolution. L'instance rch8 a un coefficient $\sigma$ proche de 0 ainsi qu'un coefficient $\rho$ moyennement élevé, de plus, elle est de faible taille, c'est l'instance qui semble la plus facile à résoudre. L'instance raphv et raphy ont un ordre de difficulté similaire,  L'instance rch10 à un très faible coefficient $\sigma$, elle doit être plus facile à résoudre que l'instance rarep pour qui le coefficient sigma est moyennement élevé. Ces deux dernières semble être les instances les plus difficiles à résoudre. Cette série d'observations et de raisonnement est corroboré par les résultats obtenus par \cite{Chhel2013}.

\subsection{Recherche exacte}
\subsubsection{Introduction}
Nous présentons les heuristiques ayant été mise en place pour la résolution d'instance MIN-PCM. Chaque heuristique est abordée de façon indépendante. Une comparaisons entre toute les heuristiques est présenté dans la sous section \ref{sectCompar}. Les comparaisons se font sur l'instance réelle rch10 et l'instance pseudo-aléatoire s3836-0.

Une comparaison entre la meilleure combinaison d'heuristique obtenu et l'heuristique "CCD" proposé par \cite{Chhel2013} avec le solveur \textit{Exact-Proj-Car} est présenté à la fin de la cette section.
\subsubsection{Algorithmes généraux de résolution}

Dans cette sous section, nous présentons une méthode générale qui permet de résoudre le MIN-PCM.

\begin{algorithm}
	\textbf{booléen minimise\_caractérisation\_instance ($Groupes$, $n$)}\\
	\tcp
	{
		$Groupes$ est un ensemble contenant tous les groupes de l'instance\\
		$n$ correspond aux nombres de gènes de l'instance
	}
	$caracterise \leftarrow$ VRAI\\
	$k \leftarrow n$ \tcp{k correspond au nombre de gènes pouvant caractériser l'instance}
	\Tq {$caracterise =$ VRAI}
	{
		$k \leftarrow k-1$\\
		$caracterise \leftarrow $caractérise\_instance ($Groupes$, $k$, $n$)\\
	}
	afficher("La caractérisation minimale est de taille " $k+1$)\\
	\caption{Algorithme de minimisation du problème de caractérisation multiple}
	\label{algoMinPCM}
\end{algorithm}

\begin{algorithm}
	\textbf{booléen caractérise\_instance ($Groupes$, $k$, $n$)}\\
	\tcp
	{
		$Groupes$ est un ensemble contenant tous les groupes de l'instance\\
		$k$ correspond au nombre de gène souhaité pour la caractérisation\\
		$n$ correspond aux nombres de gènes de l'instance
	}	
	\PourTous {$combinaison$ de $C_n^k$}
	{
		$DejaVus \leftarrow \{ \}$\\
		$caracteriseTemp \leftarrow$ VRAI\\
		\PourTous {$gRef \in Groupes$ }
		{
			$DejaVus \leftarrow DejaVus \cup \{gRef\}$\\
			\PourTous {$gComp \in Groupes \backslash DejaVus$}
			{
				\Si {$\neg$ caractérise\_groupes($combinaison$,$gRef$,$gComp$)}
					{
					$caracteriseTemp \leftarrow$ FAUX\\
					Sortir de la boucle
					}
			}
			\Si {$caracteriseTemp=$FAUX} {Sortir de la boucle}
		}
		\Si {$caracteriseTemp=$ VRAI} {\Retour {VRAI}}
		\tcp{Sinon combinaison suivante}
	}
	afficher("Il n'existe pas de caractérisation de taille " $k$)\\
	\Retour{FAUX}
	\caption{Algorithme de caractérisation d'une instance MIN-PCM pour une taille $k$}
	\label{algoCaractInstance}
\end{algorithm}

\begin{algorithm}
	\textbf{booléen caractérise\_groupes ($combinaison$,$g1$,$g2$)}\\
	\tcp{$e1$ et $e2$ sont les entités des groupes $g1$ et $g2$ }				
	\PourTous {$e1 \in g1$ }
	{
		\PourTous {$e2 \in g2$}
		{
			$temp \leftarrow$ FAUX\\
			\PourTous {$i \in combinaison$}
			{
				\Si {$e1[i] \neq e2[i]$} 
					{
						$temp \leftarrow$ VRAI\\
						Sortir de la boucle
					}
			}
			\Si {$temp = $FAUX \tcp{$g1$ et $g2$ ne sont pas caractérisable avec $combinaison$}} {\Retour {FAUX}}
		}
	}
	\Retour {VRAI}	
	\caption{Algorithme de caractérisation de groupes}
	\label{algoCaractGroupes}
\end{algorithm}

L'algorithme présenté dans la figure \ref{algoMinPCM} cherche la plus petite caractérisation possible pour une instance donnée. Il prend en entrée un ensemble de groupe $Groupes$ qui contient tout les groupes de l'instance et un entier $n$ qui correspond aux nombres de gènes de l'instance. Au début de l'algorithme, une variable booléenne $caracterise$ est instanciée à $VRAI$ et un entier $k$, qui correspondra au nombre de gènes pouvant caractériser une instance, est instancié à $n$. En effet, la caractérisation la plus évidente et immédiate est la caractérisation de taille $n$. Nous entrons ensuite dans une boucle qui va avoir pour rôle de minimiser le plus possible la variable $k$. On sort de cette boucle lorsque plus aucune caractérisation n'est possible, c'est à dire lorsque nous avons trouvé la borne minimal du MIN-PCM. Pour cela, il faut que la variable $caracterise$ soit instancié à faux, ceci ne peut se faire que par l'appel à l'algorithme \emph{caractérise\_instance} présenté dans la figure \ref{algoCaractInstance}.


Cet algorithme prend en entrée un ensemble de groupe $Groupes$ qui contient tout les groupes de l'instance, un entier $k$, qui correspond au nombre de gènes souhaité pour la caractérisation et un entier $n$ qui correspond au nombre de gènes de l'instance. Nous entrons dans une première boucle (niveau 1) qui génère les combinaisons $combinaison$ de $C_n^k$. La variable $DejaVus$ est instancié comme étant un ensemble vide de groupe. Une variable booléenne $caracteriseTemp$ est initialisé à $VRAI$. Nous entrons alors dans une seconde boucle (niveau 2), qui va ouvrir une nouvelle boucle (niveau 3) afin de tester si tout les groupes de $Groupes$ peuvent caractériser les groupes de $Groupes \backslash DejaVus$, auquel cas, nous avons une caractérisation de taille $k$ avec la combinaison $combinaison$. La mise à jour de $DejaVus$ au niveau 2 a pour effet de ne pas tester plusieurs fois des groupes ayant déjà été testé. Dès lors que la variable $caracteriseTemp$ est instancié à $FAUX$, un mécanisme de sortie de boucle permet de tester directement la prochaine combinaison de $C_n^k$. Si en sortie de boucle de niveau 2, la variable $caracteriseTemp$ est toujours instancié à $VRAI$, cela signifie que la combinaison courante caractérise l'instance, l'algorithme s'arrête alors en retournant la valeur booléenne $VRAI$. Si nous arrivons en sortie de boucle de niveau 1, cela signifie que toute les combinaisons de $C_n^k$ ont été testé et que aucune d'entre elles n'a pu caractériser l'instance. Dans ce cas, l'algorithme s'arrête en retournant la valeur booléenne $FAUX$. Dans cet algorithme, nous faisons appel à la fonction \emph{caractérise\_groupes} pour savoir si deux groupes différents peuvent être caractérisé avec une combinaison $combinaison$. Nous présentons cette fonction dans la figure \ref{algoCaractGroupes}.


Cette fonction permet de savoir si deux groupes $g1$ et $g2$ sont caractérisables avec une combinaison $combinaison$ donné. Nous notons $e1$(resp.$e2$) la variable qui va contenir une après l'autre les entités du groupe $g1$(resp.$g2$). Les entités de chacun des groupes ($e1$ et $e2$) sont comparer deux à deux sur la présence/absence des gènes définit par la combinaison $combinaison$. Si deux entités sont identiques sur ces gènes alors on ne peut pas caractériser les deux groupes avec cette combinaison(et a fortiori, on ne peut pas non plus caractériser l'instance avec cette combinaison). Dès lors, l'algorithme s'arrête immédiatement en retournant la valeur boolénne $FAUX$. Si toute les comparaisons possibles entre $e1$ et $e2$ ont été faite, cela signifie que les deux groupes $g1$ et $g2$ sont caractérisable avec la combinaison $combinaison$. L'algorithme s'arrête alors en retournant la valeur booléenne $VRAI$.



\subsubsection{Heuristique de trie sur les gènes }
\paragraph{Trie des gènes par taux de similarité $\mathcal{T}$}
Les outils mis en place pour définir ce qu'est une instance difficile vont maintenant nous permettre d'obtenir de nouvelles heuristique. Dans cette section, nous ordonnons les gènes par ordre croissant sur leur taux de similarité globale $\mathcal{T}$. Dès lors, nous parcourons en priorité les gènes présentant un faible taux de similarité. Ce trie par $\mathcal{T}$ permet de générer un arbre de recherche(TODO:DEFINIR DE FACON FORMELLE CET ARBRE) qui a pour particularité de présenter en priorité les branches ayant le plus de chances de fournir une éventuelle solution. Un tel arbre de recherche nous permet de caractériser bien plus vite une instance. Le coût de calcul de ce trie est insignifiant et est effectué de façon unique avant le lancement de l'algorithme de résolution.

\subparagraph{Résultats}

%\begin{figure}
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_tau_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_tau_temps.tex}
%	\end{minipage}
%\caption{Heuristique $\mathcal{T}$ sur rch10}
%\end{figure}
%
%\begin{figure}
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_tau_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_tau_temps.tex}
%	\end{minipage}
%\caption{Heuristique $\mathcal{T}$ sur s3836-0}
%\end{figure}

Sur l'instance réelle rch10, on constante que le nombre de comparaisons d'entités  et le temps d'éxécution est considérablement diminué par l'heuristique. Cependant, on s'aperçoit que cette heuristique a peu d'influence (voir même une influence négative dans le cas présent) sur la résolution d'instance aléatoire car celles-ci ne disposent pas de variations significative entre les $\mathcal{T}$ des gènes. La possibilité que l'influence soit négative nous permet de conclure que le trie des gènes par $\mathcal{T}$ n'est pas un trie optimal. 


\subsubsection{Heuristique de trie sur les groupes}
\paragraph{Trie des groupes par taux de similarité $\Gamma$}
Lors de la précédente section, nous avons ordonné les gènes d'après leurs $\mathcal{T}$. Ici, nous souhaitons ordonner les entités dans le but de pouvoir effectuer des retour arrière(backtrack) lorsque nous parcourons notre arbre de recherche. Nous définissons alors les concepts de taux de similarité locale et de taux se similarité globale d'un groupe.

\begin{definition}
Le \textbf{taux de similarite locale $\tau(g,g')$ d'un groupe $g$} par rapport à un groupe $g'$ correspond à la moyenne des sommes des moyennes des valeurs du masque de $g$ et $g'$.\\
Formellement, soit $g$ et $g'$ deux groupes d'une instance $\mathcal{I}$, $M_g$ le masque du groupe $g$, $M_{g'}$ le masque du groupe $g'$, $M_g[i]$ la valeur du masque du groupe $g$ en position $i$,
$$ \tau(g,g')= \frac{\sum_{i=1}^{|\mathcal{X}|}(\frac{M_g[i]+M_{g'}[i]}{2})}{|\mathcal{X}|}$$
\end{definition}

\begin{definition}
Le \textbf{taux de similarité globale $\Gamma(g)$ d'un groupe $g$} correspond à la moyenne de ses taux de similarité locaux.\\
Formellement, soit $g$ le groupe d'une instance $\mathcal{I}$,
$$ \Gamma(g)=\frac{\sum_{g'=1}^{|\mathcal{G}|}\tau(g,g') /g \neq g'}{|\mathcal{G}|-1} $$
\end{definition}

Pour caractériser une instance, nous devons comparer chaque entité n'appartenant pas au même groupe entre elles. Notre idée est de placer les entités ayant le plus de chance de ne pas caractériser l'instance en premier car cela nous permettrait d'effectuer une coupure le plus haut possible dans notre arbre de recherche. Pour cela nous trions les groupes par ordre décroissant sur leurs taux de similarité globaux $\Gamma$.



\subparagraph{Résultats}

%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_gamma_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_gamma_temps.tex}
%	\end{minipage}
%\caption{Heuristique $\Gamma$ sur rch10}
%\end{figure}
%
%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_gamma_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_gamma_temps.tex}
%	\end{minipage}
%\caption{Heuristique $\Gamma$ sur s3836-0}
%\end{figure}
%
%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_gamma_vs_gamma_dynamique_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_gamma_vs_gamma_dynamique_temps.tex}
%	\end{minipage}
%\caption{Comparaisons heuristique $\Gamma$ et heuristique $\Gamma$ dynamique}
%\end{figure}

Nous constatons que notre heuristique permet de baisser significativement le nombre de comparaisons .

\subsubsection{Heuristique de retour en arrière (backtracking)}
\paragraph{Heuristique des plus mauvais d'abord (pmda)}
Lorsque nous parcourons une instance pour une caractérisation de taille $k$. On peut affecter un poids sur la paire d'entités comparés deux à deux sur les indices de la combinaison courante.

Formellement, soit $e_a$, $e_z$ deux entités n'appartenant pas au même groupe, $\mathcal{C}$ une combinaison de $\mathcal{C}_{|\mathcal{X}|}^k$, $P$ le poids de la paire $\{e_a,e_z\}$.
$$ P = |\{i / e_a(i)=e_z(i), \forall i \in \mathcal{C}\}| $$

\begin{definition}
Si $P>=k-1$ alors la \textbf{paire d'entités $\{e_a,e_z\}$ est critique} car lors du parcours de la prochaine combinaisons, cette paire à la plus forte probabilité de permettre une coupure dans l'arbre de recherche.
\end{definition}

\subparagraph{Exemple :}
Soit les 2 entités suivante:
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline 
Groupe & \backslashbox{Entités}{Gènes} & g1 & g2 & g3 & g4 & g5 & g6 \\ 
\hline 
1 & e1 & 1 & 0 & 1 & 0 & 0 & 0 \\ 
\hline 
20 & e400 & 1 & 0 & 0 & 0 & 0 & 1 \\ 
\hline 
\end{tabular}
\end{center}
Supposons que nous sommes dans le cas d'une caractérisation de taille 3, nous parcourons les combinaisons de $\mathcal{C}_6^3 $. Supposons que le groupe 1 soit de taille 1, si nous sommes à la comparaison entre e1 et e400, cela signifie que nous avons déjà effectué 399 comparaisons d'entités. 

Regardons alors la combinaison courante 123 : nous apercevons que seul g3 permet la caractérisation. Comme plusieurs des combinaisons suivantes ne différeront que d'un élément, cet paire d'entités \{e1,e400\} à la plus forte probabilité d'être similiraire lors de la prochaine combinaison, nous gardons donc en mémoire cet ensemble qui a un poids égale à $k-1$.

Supposons que 123 n'ai pas caractérisé notre instance, nous parcourons alors 124 : nous commençons par parcourir les ensembles critiques obtenus lors du parcours précédent, soit la comparaison entre e1 et e400. Le poids est alors égale à $k$, ce qui signifie que nous pouvons arrêter notre recherche sur cette combinaison (car celle ci ne pourra en aucun cas caractériser l'instance). Cependant nous gardons en mémoire cet ensemble critique. Notons que nous avons fait là l'économie de 399 comparaisons d'entités.

Nous parcourons alors 125 : même constat , de nouveau une économie de 399 comparaisons d'entités.

Nous parcourons alors 126 : aucun effet, mais la paire \{e1,e400\} est toujours considérer comme critique.

Nous parcourons alors 134 : aucun effet, mais la paire  \{e1,e400\} n'est plus considéré comme critique car son poids $<k-1$.

\subparagraph{Résultats}
%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_pmda_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_pmda_temps.tex}
%	\end{minipage}
%\caption{Heuristiques pmda sur rch10}
%\end{figure}
%
%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_pmda_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_pmda_temps.tex}
%	\end{minipage}
%\caption{Heuristiques pmda sur s3836-0}
%\end{figure}

On constante que le nombre de comparaisons d'entités ainsi que le temps d'éxécution sont considérablement diminué par l'heuristique.

Ce type de résultat ayant été observé systématiquement sur un jeu de 15 instances(aléatoire et réelle), on peut conclure que cette heuristique est efficace.

\paragraph{Heuristique des valeurs tabous}
\subparagraph{Résultats}

%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_tabou_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/rch10_sh_vs_tabou_temps.tex}
%	\end{minipage}
%\caption{Heuristique tabou sur rch10}
%\end{figure}
%
%\begin{figure}[H]
%\centering
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_tabou_nbComp.tex}
%	\end{minipage}
%	\begin{minipage}[c]{0.49\linewidth}
%	\centering
%	\input{./figure/s3836_sh_vs_tabou_temps.tex}
%	\end{minipage}
%\caption{Heuristique tabou sur s3836-0}
%\end{figure}



\subsection{Comparaisons entre heuristique}
\label{sectCompar}
\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\begin{axis}[
legend entries={rch10 trie par $\mathcal{T}$,rch10 par $\Gamma$,rch10 pmda noMaj,rch10 pmda maj,rch10 tabou},
%legend style={at={(0.5,1.03)},anchor=south},legend columns=3
xlabel={Caractérisation de taille k},
ylabel={Nombre de comparaisons d'entités},
xmin={12},
xmax={35},
%ymax={1000000000}
%title={Résolution sans heuristique de rch10 et s3836-0 sur les comparaisons}
]
\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/tau_rch10.dat};
\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/gamma_rch10.dat};
\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/pmda_noMaj_rch10.dat};
\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/pmda_maj_rch10.dat};
\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/tabou_rch10.dat};
%\addplot +[mark=none] table[x=k,y=nbComp]{./resultats/ratio_rch10.dat};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{Comparaisons des heuristiques sur rch10: nombre de comparaisons}
\end{figure}


\begin{figure}[H]
\begin{center}
\begin{tikzpicture}
\begin{axis}[
legend entries={rch10 trie par $\mathcal{T}$,rch10 par $\Gamma$,rch10 pmda noMaj,rch10 pmda maj,rch10 tabou},
%legend style={at={(0.5,1.03)},anchor=south},legend columns=3
xlabel={Caractérisation de taille k},
ylabel={Nombre de comparaisons d'entités},
xmin={12},
xmax={35},
%ymax={100}
%title={Résolution sans heuristique de rch10 et s3836-0 sur les comparaisons}
]
\addplot +[mark=none] table[x=k,y=temps]{./resultats/tau_rch10.dat};
\addplot +[mark=none] table[x=k,y=temps]{./resultats/gamma_rch10.dat};
\addplot +[mark=none] table[x=k,y=temps]{./resultats/pmda_noMaj_rch10.dat};
\addplot +[mark=none] table[x=k,y=temps]{./resultats/pmda_maj_rch10.dat};
\addplot +[mark=none] table[x=k,y=temps]{./resultats/tabou_rch10.dat};
%\addplot +[mark=none] table[x=k,y=temps]{./resultats/ratio_rch10.dat};
\end{axis}
\end{tikzpicture}
\end{center}
\caption{Comparaisons des heuristiques sur rch10: temps d'exécution}
\end{figure}

\subsubsection{Résultats}

Nous présentons ici les résultats obtenus avec notre solveur \emph{Exact-Proj-Car2} (EPC2) qui fonctionne avec toute les meilleures heuristiques présentées dans cette section. Nous pouvons ainsi comparer nos résultats avec ceux obtenus par [CHHEL et al.,2013].

La colonne \textit{temps} indique le temps cumulé depuis le début de la recherche à $k=|\cal{X}|$.

\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
\multirow{2}*{Instances} & \multirow{2}*{Entités(SR)} & \multirow{2}*{Gènes(SR)}& \multirow{2}*{$\Delta\cal{T}$}&  \multirow{2}*{$\rho$} & \multirow{2}*{$\sigma$} & \multirow{2}*{PL} & \multirow{2}*{EPC} & \multicolumn{2}{c|}{EPC2} \\
\cline{9-10} 
 & & & & & & & & k & temps \\
\hline 
s301-0 & 500 & 400 & 0.0247583 & 0.034 & 0.999917 & - & 13 & 13 & 2.07279\\ 
\hline 
s326-0 & 500 & 500 & 0.0264423 & 0.033 & 1 & - & 13 & 13 & 1.70796 \\ 
\hline 
s413-30 & 500 & 600 & 0.027368 & 0.035 & 1 & - & 13 & 13 & 1.05077\\ 
\hline 
s555-20 & 800 & 800 & 0.028946 & 0.039 & 0.999833 & - & 13 & 13 & 14.9249\\ 
\hline 
s625-20 & 500 & 1000 & 0.0270316 & 0.035 & 1 & - & 13 & 13 & 1.63653 \\ 
\hline 
s754-10 & 600 & 200 & 0.0266147 & 0.034 & 1 & - & 13 & \textcolor{red}{14} & 0.366073\\ 
\hline 
s882-20 & 600 & 400 & 0.0240376 & 0.032 & 1 & - & 13 & 13 & 543.176 \\ 
\hline 
s2501-70 & 800 & 800 & 0.0243325 & 0.033 & 1 & - & 15 & \textcolor{blue}{14} & \textcolor{cyan}{282.935} \\ 
\hline 
s31294-50 & 200 & 1000 & 0.0493203 & 0.065 & 0.9928 & 10 & 10 & 10 & 381.108 \\ 
\hline 
s3836-0 & 1000 & 1000 & 0.0187905 & 0.024 & 1 & - & 16 & \textcolor{blue}{15} & \textcolor{cyan}{13.072} \\ 
\hline 
rch8 & 132 (56) & 37 (27) & 0.339488 & 0.569 & 0.0670193 & \textbf{9} & \textbf{9} & \textbf{9} & 0.038407 \\ 
\hline 
raphv & 109 (108) & 155 (68) & 0.301636 & 0.588 & 0.419118 & \textbf{6} & \textbf{6} & \textbf{6} & 2.0551 \\ 
\hline 
raphy & 113 (112) & 155 (70) & 0.293601 & 0.609 & 0.667857 & \textbf{6} & \textbf{6} & \textbf{6} & 6.84672 \\ 
\hline 
rarep & 112 & 155 (72) & 0.295408 & 0.651 & 0.501984 & \textbf{12} & 39 & \textcolor{blue}{16} & 206.037 \\ 
\hline 
rch10 & 173 (112) & 98 (86) & 0.237992 & 0.626 & 0.0938845 & \textbf{10} & 25 & \textcolor{blue}{11} & 383.006\\ 
\hline 
\end{tabular} 
\end{center}

Nous avons placer en bleu les caractérisations de taille inférieur à EPC. Les temps de couleur cyan permettent de souligner la rapidité d'éxécution de EPC2 par rapport à EPC:  EPC2 caractérise l'instance s3836-0 en 13 secondes pour un k=15 alors que EPC ne réduit pas en dessous de k=16 en 10 minutes. Nous observons le même type de phénomène sur l'instance s2501-70. Notons toutefois que l'instance s754-10 est moins bien caractériser par EPC2, nous pensons que dans ce cas précis, l'influence du trie par $\cal{T}$ est négative, cela est du à $\Delta\cal{T}$ proche de 0. Notre solveur réduit de façon significative les caractérisations des instances réelles rarep et rch10. 


\subsection{Recherche incomplète}
\subsubsection{Résultats}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|}
\hline 
\multirow{2}*{Instances} & \multirow{2}*{Entités(SR)} & \multirow{2}*{Gènes(SR)}&\multirow{2}*{$\Delta\cal{T}$} & \multirow{2}*{$\rho$} & \multirow{2}*{$\sigma$} & \multirow{2}*{PL} & \multirow{2}*{LSPC} & \multicolumn{3}{c|}{Roulette proportionelle} \\
\cline{9-11} 
 & & & & & & & & k & temps & itérations \\
\hline 
s301-0 & 500  & 400 & 0.0247583 & 0.034 & 0.999917 & - & 14 & \textcolor{blue}{13} & 421.005 & 1612515 \\ 
\hline 
s326-0 & 500 & 500 & 0.0264423 & 0.033 & 1 & - & 14 & \textcolor{blue}{13} & 93.2472 & 390166\\ 
\hline 
s413-30 & 500 & 600 & 0.027368 & 0.035 & 1 & - & 13 & 13 & 428.634 & 1388939 \\ 
\hline 
s555-20 & 800 & 800 & 0.028946 & 0.039 & 0.999833 & - & 13 & 13 & 395.024 & 1286275 \\ 
\hline 
s625-20 & 500 & 1000 & 0.0270316 & 0.035 & 1 & - & 13 & 13 & 415.878 & 1359740 \\ 
\hline 
s754-10 & 600 & 200 & 0.0266147 & 0.034 & 1 & - & 14 & 14 & 25.8758 & 84672\\ 
\hline 
s882-20 & 600 & 400 & 0.0240376 & 0.032 & 1 & - & 14 & 14 & 3.02248 & 9113\\ 
\hline 
s2501-70 & 800 & 800 & 0.0243325 & 0.033 & 1 & - & 15 & 15 & 4.24 & 4350 \\ 
\hline 
s31294-50 & 200 & 1000 & 0.0493203 & 0.065 & 0.9928 & 10 & 11 & 11 & 0.962858 & 5273\\ 
\hline 
s3836-0 & 1000 & 1000 & 0.0187905 & 0.024 & 1 & - & 16 & 16 & 5.26595 & 1006 \\ 
\hline
rch8 & 132 (56) & 37 (27) & 0.339488 & 0.569 & 0.0670193 & \textbf{9} & 9 & 9 & 0.031263 & 22440 \\ 
\hline 
raphv & 109 (108) & 155 (68) & 0.301636 & 0.588 & 0.419118 & \textbf{6} & 9 & \textcolor{blue}{6} & 0.656676 & 470528\\ 
\hline 
raphy & 113 (112) & 155 (70)& 0.293601 & 0.609 & 0.667857 & \textbf{6} & 8 & \textcolor{blue}{6} & 0.87275 & 524344\\ 
\hline 
rarep & 112 & 155 (72) & 0.295408 & 0.651 & 0.501984 & \textbf{12} & 14 & 14 & 36.6272 & 17793513
\\ 
\hline 
rch10 & 173 (112) & 98 (86) & 0.237992 & 0.626 & 0.0938845 & \textbf{10} & 15 & \textcolor{blue}{12} & 65.6151 & 35676187\\ 
\hline 
\end{tabular} 
\end{center}


\subsection{Générateur d'instance difficile}
\subsubsection{Résultats} 
